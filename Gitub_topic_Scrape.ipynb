{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "944d77a0-ca18-4804-81fe-958100d6d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"https://github.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55cf04eb-39f1-46d8-84a7-dadf275f35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_title(doc):\n",
    "    selection_class = \"f3 lh-condensed mb-0 mt-1 Link--primary\"\n",
    "    topic_title_tags = doc.find_all('p', {'class' : selection_class})\n",
    "\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles\n",
    "\n",
    "def get_topic_des(doc):\n",
    "    topic_desc_tag = doc.find_all('p', {'class' : 'f5 color-fg-muted mb-0 mt-1'})\n",
    "    topic_descriptions = []\n",
    "    for tag in topic_desc_tag:\n",
    "        topic_descriptions.append(tag.text.strip())\n",
    "    return topic_descriptions\n",
    "\n",
    "def get_topic_url(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class' : 'no-underline flex-1 d-flex flex-column'})\n",
    "    topic_urls = []\n",
    "    \n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag[\"href\"])\n",
    "    return topic_urls\n",
    "\n",
    "\n",
    "def scrape_topics():\n",
    "    topic_url = \"https://github.com/topics\"\n",
    "    res = requests.get(topic_url)\n",
    "    if(res.status_code != 200):\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "\n",
    "    doc = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    topic_dict = {\n",
    "        'title' : get_topic_title(doc),\n",
    "        'description' : get_topic_des(doc),\n",
    "        'url' : get_topic_url(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3518737e-d1ef-42af-935c-bd208d179d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "     # Download the page\n",
    "    res = requests.get(topic_url)\n",
    "\n",
    "    # checking the status code\n",
    "    if res.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "\n",
    "    # Parse using beautifulsoup\n",
    "    topic_doc = BeautifulSoup(res.text, 'html.parser')\n",
    "    return topic_doc\n",
    "\n",
    "def parse_star_count(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "    if stars_str[-1] == 'k':\n",
    "        return int(float(stars_str[:-1])*1000)\n",
    "    return int(stars_str)\n",
    "\n",
    "def get_repo_info(h_tag,star_tag):\n",
    "    a_tag = h_tag.find_all('a')\n",
    "    username = a_tag[0].text.strip()\n",
    "    repo_name = a_tag[1].text.strip()\n",
    "    repo_url = base_url + a_tag[1][\"href\"]\n",
    "    star = parse_star_count(star_tag.text)\n",
    "    return username, repo_name, repo_url, star\n",
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    \n",
    "    # repo_tags containing repo_name, repo_url and username\n",
    "    repo_tags = topic_doc.find_all('h3', {'class' : 'f3 color-fg-muted text-normal lh-condensed'})\n",
    "    star_tag = topic_doc.find_all('span',{'id' : 'repo-stars-counter-star'})\n",
    "\n",
    "    topic_repos_dict = {\n",
    "        'username' : [],\n",
    "        'repo_name' : [],\n",
    "        'stars' : [],\n",
    "        'repo_url' : [],\n",
    "    }\n",
    "\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i],star_tag[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[3])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[2])\n",
    "\n",
    "    return pd.DataFrame(topic_repos_dict)\n",
    "\n",
    "def scrape_topic(topic_url, topic_name):\n",
    "    fname = topic_name + '.csv'\n",
    "    if os.path.exists(fname):\n",
    "        print(\"The file {} already exists. Skipping..\".format(fname))\n",
    "        return\n",
    "        \n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(fname, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22a249ba-c9eb-4c21-9da2-2036042834f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic_repos():\n",
    "    print(\"Scraping list of topics\")\n",
    "    topics_df = scrape_topics()\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top reops for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'],row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70533ee0-0f19-4e07-875c-6861ff007fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top reops for \"3D\"\n",
      "Scraping top reops for \"Ajax\"\n",
      "Scraping top reops for \"Algorithm\"\n",
      "Scraping top reops for \"Amp\"\n",
      "Scraping top reops for \"Android\"\n",
      "Scraping top reops for \"Angular\"\n",
      "Scraping top reops for \"Ansible\"\n",
      "Scraping top reops for \"API\"\n",
      "Scraping top reops for \"Arduino\"\n",
      "Scraping top reops for \"ASP.NET\"\n",
      "Scraping top reops for \"Awesome Lists\"\n",
      "Scraping top reops for \"Amazon Web Services\"\n",
      "Scraping top reops for \"Azure\"\n",
      "Scraping top reops for \"Babel\"\n",
      "Scraping top reops for \"Bash\"\n",
      "Scraping top reops for \"Bitcoin\"\n",
      "Scraping top reops for \"Bootstrap\"\n",
      "Scraping top reops for \"Bot\"\n",
      "Scraping top reops for \"C\"\n",
      "Scraping top reops for \"Chrome\"\n",
      "Scraping top reops for \"Chrome extension\"\n",
      "Scraping top reops for \"Command-line interface\"\n",
      "Scraping top reops for \"Clojure\"\n",
      "Scraping top reops for \"Code quality\"\n",
      "Scraping top reops for \"Code review\"\n",
      "Scraping top reops for \"Compiler\"\n",
      "Scraping top reops for \"Continuous integration\"\n",
      "Scraping top reops for \"C++\"\n",
      "Scraping top reops for \"Cryptocurrency\"\n",
      "Scraping top reops for \"Crystal\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topic_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a06646-f3e9-490d-9986-eacd0efe73b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
